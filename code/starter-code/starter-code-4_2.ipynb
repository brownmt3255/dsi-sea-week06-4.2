{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Lab\n",
    "\n",
    "In this lab we will further explore Scikit's and NLTK's capabilities to process text. We will use the 20 Newsgroup dataset, which is provided by Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data taype is `data_train`\n",
    "> sklearn.datasets.base.Bunch\n",
    "- Is it like a list? Or like a Dictionary? or what?\n",
    "> Dict\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point, what does it look like?\n",
    "> A blurb of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <type 'list'>\n",
      "# of Data points:  2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Type: \", type(data_train.data)\n",
    "print '# of Data points: ', len(data_train.data)\n",
    "data_train.data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data\n",
    "- how big is the feature dictionary\n",
    "- repeat eliminating english stop words\n",
    "- is the dictionary smaller?\n",
    "- transform the training data using the trained vectorizer\n",
    "- what are the 20 words that are most common in the whole corpus?\n",
    "- what are the 20 most common words in each of the 4 classes?\n",
    "- evaluate the performance of a Lotistic Regression on the features extracted by the CountVectorizer\n",
    "    - you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "- try the following 3 modification:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df\n",
    "    - use a fixed vocabulary of size 80 combining the 20 most common words per group found earlier\n",
    "- for each of the above print a confusion matrix and investigate what gets mixed\n",
    "> Anwer: not surprisingly if we reduce the feature space we lose accuracy\n",
    "- print out the number of features for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize a standard CountVectorizer and fit the training data\n",
    "v = CountVectorizer()\n",
    "X_train_vect = v.fit_transform(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26879)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how big is the feature dictionary\n",
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat eliminating english stop words\n",
    "# transform the training data using the trained vectorizer\n",
    "v = CountVectorizer(stop_words='english')\n",
    "X_train_vect = v.fit_transform(data_train.data)\n",
    "\n",
    "# is the dictionary smaller?\n",
    "print \"Yes\"\n",
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'data': 0,\n",
       " u'does': 1,\n",
       " u'don': 2,\n",
       " u'edu': 3,\n",
       " u'god': 4,\n",
       " u'good': 5,\n",
       " u'graphics': 6,\n",
       " u'image': 7,\n",
       " u'jesus': 8,\n",
       " u'just': 9,\n",
       " u'know': 10,\n",
       " u'like': 11,\n",
       " u'nasa': 12,\n",
       " u'people': 13,\n",
       " u'say': 14,\n",
       " u'space': 15,\n",
       " u'think': 16,\n",
       " u'time': 17,\n",
       " u'use': 18,\n",
       " u'way': 19}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the 20 words that are most common in the whole corpus?\n",
    "top_20 = CountVectorizer(stop_words='english', max_features = 20)\n",
    "top_20.fit_transform(data_train.data)\n",
    "top_20.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi,\\n\\nI've noticed that if you only save a mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nSeems to be, barring evidence to the contr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n &gt;In article &lt;1993Apr19.020359.26996@sq.sq.c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have a request for those who would like to s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AW&amp;ST  had a brief blurb on a Manned Lunar Exp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  class\n",
       "0  Hi,\\n\\nI've noticed that if you only save a mo...      1\n",
       "1  \\n\\nSeems to be, barring evidence to the contr...      3\n",
       "2  \\n >In article <1993Apr19.020359.26996@sq.sq.c...      2\n",
       "3  I have a request for those who would like to s...      0\n",
       "4  AW&ST  had a brief blurb on a Manned Lunar Exp...      2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the 20 most common words in each of the 4 classes?\n",
    "\n",
    "X = pd.DataFrame(data_train.data, columns = ['data'])\n",
    "y = pd.DataFrame(data_train.target, columns = ['class'])\n",
    "df_common = pd.concat([X, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{u'people': 12, u'time': 17, u'argument': 0, u'say': 15, u'religion': 13, u'atheists': 2, u'don': 6, u'jesus': 8, u'does': 5, u'way': 19, u'true': 18, u'atheism': 1, u'said': 14, u'just': 9, u'think': 16, u'bible': 4, u'like': 11, u'god': 7, u'believe': 3, u'know': 10}\n",
      "1\n",
      "{u'format': 7, u'data': 2, u'image': 11, u'gif': 9, u'ftp': 8, u'graphics': 10, u'does': 3, u'software': 18, u'available': 0, u'use': 19, u'pub': 17, u'like': 15, u'images': 12, u'file': 5, u'edu': 4, u'jpeg': 13, u'color': 1, u'program': 16, u'files': 6, u'know': 14}\n",
      "2\n",
      "{u'people': 12, u'time': 17, u'data': 0, u'just': 3, u'year': 19, u'space': 16, u'launch': 4, u'orbit': 11, u'new': 10, u'don': 1, u'lunar': 6, u'shuttle': 15, u'like': 5, u'earth': 2, u'satellite': 14, u'moon': 8, u'program': 13, u'mission': 7, u'nasa': 9, u'use': 18}\n",
      "3\n",
      "{u'life': 11, u'people': 13, u'time': 18, u'say': 16, u'jesus': 8, u'does': 4, u'way': 19, u'think': 17, u'don': 5, u'said': 15, u'just': 9, u'did': 3, u'bible': 1, u'good': 7, u'believe': 0, u'point': 14, u'like': 12, u'god': 6, u'christian': 2, u'know': 10}\n"
     ]
    }
   ],
   "source": [
    "listy = []\n",
    "for a in range(4):\n",
    "    top_20 = CountVectorizer(stop_words='english', max_features = 20)\n",
    "    top_20.fit_transform(df_common.ix[df_common['class']== a]['data'])\n",
    "    \n",
    "    listy.append([x for x in top_20.vocabulary_])\n",
    "    print a\n",
    "    print top_20.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.745011086475\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     187      16      46      70\n",
      "1      13     345      28       3\n",
      "2      22      23     333      16\n",
      "3      67      14      27     143\n",
      "Word Count: 26576\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer\n",
    "# you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "\n",
    "def log_reg_score(vectorizer):\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    y_train = data_train.target\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    y_test = data_test.target\n",
    "\n",
    "    model_log_reg = LogisticRegression()\n",
    "    model_log_reg.fit(X_train, y_train)\n",
    "    y_predictions = model_log_reg.predict(X_test)\n",
    "    confusion_matrix_ = confusion_matrix(y_test, y_predictions)\n",
    "    \n",
    "    print 'Score:', model_log_reg.score(X_test, y_test)\n",
    "    print pd.DataFrame(confusion_matrix_, columns = ['pred_0','pred_1','pred_2','pred_3'], index = ['0','1','2','3'])    \n",
    "    print 'Word Count:', len(vectorizer.vocabulary_)\n",
    "    \n",
    "v = CountVectorizer(stop_words='english')\n",
    "log_reg_score(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 10\n",
      "Score: 0.427198817443\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     108     160      37      14\n",
      "1      23     310      55       1\n",
      "2      31     214     148       1\n",
      "3      89     129      21      12\n",
      "Word Count: 10\n",
      "\n",
      "\n",
      "max_features = 100\n",
      "Score: 0.619364375462\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     161      28      56      74\n",
      "1      19     302      59       9\n",
      "2      38      34     298      24\n",
      "3     107      19      48      77\n",
      "Word Count: 100\n",
      "\n",
      "\n",
      "max_features = 1000\n",
      "Score: 0.69696969697\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     172      15      59      73\n",
      "1      16     331      36       6\n",
      "2      28      29     312      25\n",
      "3      76      16      31     128\n",
      "Word Count: 1000\n",
      "\n",
      "\n",
      "max_features = 10000\n",
      "Score: 0.742054693274\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     186      15      46      72\n",
      "1      14     344      28       3\n",
      "2      21      27     331      15\n",
      "3      67      14      27     143\n",
      "Word Count: 10000\n",
      "\n",
      "\n",
      "min_df = 0.1\n",
      "Score: 0.441241685144\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     116     125      41      37\n",
      "1      30     287      67       5\n",
      "2      39     181     170       4\n",
      "3      88     112      27      24\n",
      "Word Count: 18\n",
      "\n",
      "\n",
      "min_df = 0.2\n",
      "Score: 0.305247597931\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0      42     205      70       2\n",
      "1      23     264     101       1\n",
      "2      31     257     105       1\n",
      "3      25     180      44       2\n",
      "Word Count: 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try the following 3 modification:\n",
    "\n",
    "#restrict the max_features\n",
    "\n",
    "for i in [10, 100, 1000, 10000]:\n",
    "    print 'max_features =', i\n",
    "    v = CountVectorizer(stop_words='english', max_features = i)\n",
    "    log_reg_score(v)\n",
    "    print '\\n'\n",
    "\n",
    "    \n",
    "for i in [.1, .2]:\n",
    "    print 'min_df =', i\n",
    "    v = CountVectorizer(stop_words='english', min_df = i)\n",
    "    log_reg_score(v)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df = 0.1\n",
      "Score: 0.746489283075\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     186      16      52      65\n",
      "1      11     341      34       3\n",
      "2      21      27     335      11\n",
      "3      59      14      30     148\n",
      "Word Count: 26558\n",
      "\n",
      "\n",
      "max_df = 0.2\n",
      "Score: 0.747967479675\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     184      15      48      72\n",
      "1       9     345      32       3\n",
      "2      19      25     336      14\n",
      "3      64      16      24     147\n",
      "Word Count: 26572\n",
      "\n",
      "\n",
      "max_df = 0.3\n",
      "Score: 0.745011086475\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     187      16      46      70\n",
      "1      13     345      28       3\n",
      "2      22      23     333      16\n",
      "3      67      14      27     143\n",
      "Word Count: 26576\n",
      "\n",
      "\n",
      "max_df = 0.4\n",
      "Score: 0.745011086475\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     187      16      46      70\n",
      "1      13     345      28       3\n",
      "2      22      23     333      16\n",
      "3      67      14      27     143\n",
      "Word Count: 26576\n",
      "\n",
      "\n",
      "max_df = 0.5\n",
      "Score: 0.745011086475\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     187      16      46      70\n",
      "1      13     345      28       3\n",
      "2      22      23     333      16\n",
      "3      67      14      27     143\n",
      "Word Count: 26576\n",
      "\n",
      "\n",
      "min_df = 0.1\n",
      "Score: 0.441241685144\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     116     125      41      37\n",
      "1      30     287      67       5\n",
      "2      39     181     170       4\n",
      "3      88     112      27      24\n",
      "Word Count: 18\n",
      "\n",
      "\n",
      "min_df = 0.2\n",
      "Score: 0.305247597931\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0      42     205      70       2\n",
      "1      23     264     101       1\n",
      "2      31     257     105       1\n",
      "3      25     180      44       2\n",
      "Word Count: 4\n",
      "\n",
      "\n",
      "min_df = 0.3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ebb0d90e03f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'min_df ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlog_reg_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-dd968980195c>\u001b[0m in \u001b[0;36mlog_reg_score\u001b[0;34m(vectorizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_reg_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Madballa55/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    843\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Madballa55/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m    732\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "# change max_df and min_df\n",
    "for i in [.1, .2, .3, .4, .5]:\n",
    "    print 'max_df =', i\n",
    "    v = CountVectorizer(stop_words='english', max_df = i)\n",
    "    log_reg_score(v)\n",
    "    print '\\n'\n",
    "\n",
    "for i in [.1, .2, .3, .4, .5]:\n",
    "    print 'min_df =', i\n",
    "    v = CountVectorizer(stop_words='english', min_df = i)\n",
    "    log_reg_score(v)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.60458240946\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     152      28      68      71\n",
      "1      16     301      62      10\n",
      "2      43      36     292      23\n",
      "3     102      21      55      73\n",
      "Word Count: 80\n"
     ]
    }
   ],
   "source": [
    "# use a fixed vocabulary of size 80 combining the 20 most common words per group found earlier\n",
    "v = CountVectorizer(stop_words='english', max_features=80)\n",
    "log_reg_score(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "- does the score improve with respect to the count vectorizer?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "- can you improve on your best score above?\n",
    "    - can you change any of the default parameters to improve it?\n",
    "- print out the number of features for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score: 0.745011086475\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     187      16      46      70\n",
      "1      13     345      28       3\n",
      "2      22      23     333      16\n",
      "3      67      14      27     143\n",
      "Word Count: 26576\n"
     ]
    }
   ],
   "source": [
    "def log_reg_score_2(vectorizer):\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "    y_train = data_train.target\n",
    "    X_test = vectorizer.transform(data_test.data)\n",
    "    y_test = data_test.target\n",
    "\n",
    "    model_log_reg = LogisticRegression()\n",
    "    model_log_reg.fit(X_train, y_train)\n",
    "    y_predictions = model_log_reg.predict(X_test)\n",
    "    confusion_matrix_ = confusion_matrix(y_test, y_predictions)\n",
    "    \n",
    "    print 'Score:', model_log_reg.score(X_test, y_test)\n",
    "    print pd.DataFrame(confusion_matrix_, columns = ['pred_0','pred_1','pred_2','pred_3'], index = ['0','1','2','3'])    \n",
    "    print 'Number of features:', vectorizer.n_features\n",
    "    \n",
    "v = CountVectorizer(stop_words='english')\n",
    "log_reg_score(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score: 0.736881005174\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     197      15      65      42\n",
      "1       9     347      32       1\n",
      "2      21      23     350       0\n",
      "3      86      18      44     103\n",
      "Number of features: 1048576\n"
     ]
    }
   ],
   "source": [
    "# Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "# Print number of features\n",
    "v = HashingVectorizer(stop_words='english')\n",
    "log_reg_score_2(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the score improve with respect to the count vectorizer? NO\n"
     ]
    }
   ],
   "source": [
    "print \"Does the score improve with respect to the count vectorizer? NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score: 0.747967479675\n",
      "   pred_0  pred_1  pred_2  pred_3\n",
      "0     198      15      65      41\n",
      "1       8     351      29       1\n",
      "2      17      21     356       0\n",
      "3      82      16      46     107\n",
      "Word Count: 26576\n"
     ]
    }
   ],
   "source": [
    "# Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "v = TfidfVectorizer(stop_words='english')\n",
    "log_reg_score(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classifier comparison\n",
    "\n",
    "Of all the vectorizers tested above, choose one that has a reasonable performance with a manageable number of features and compare the performance of these models:\n",
    "\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "\n",
    "In order to speed up the calculation it's better to vectorize the data only once and then compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listy_models = [KNeighborsClassifier(), LogisticRegression(), DecisionTreeClassifier(), SVC(), RandomForestClassifier(), ExtraTreesClassifier()]\n",
    "\n",
    "def model_score(model, v):\n",
    "    X_train = v.fit_transform(data_train.data)\n",
    "    X_test = v.transform(data_test.data)\n",
    "    y_train = data_train.target\n",
    "    y_test = data_test.target\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predictions = model.predict(X_test)\n",
    "    \n",
    "    print 'score:', model.score(X_test, y_test)\n",
    "    print  'con mat:','\\n', confusion_matrix(y_test, y_predictions)\n",
    "    print 'number of words:', len(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "score: 0.252032520325\n",
      "con mat: \n",
      "[[122 108  34  55]\n",
      " [158 101  62  68]\n",
      " [118 135  72  69]\n",
      " [ 86  80  39  46]]\n",
      "number of words: 26572\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "score: 0.749445676275\n",
      "con mat: \n",
      "[[194  14  66  45]\n",
      " [  7 351  30   1]\n",
      " [ 13  22 359   0]\n",
      " [ 79  16  46 110]]\n",
      "number of words: 26572\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "score: 0.593495934959\n",
      "con mat: \n",
      "[[142  53  43  81]\n",
      " [ 16 319  39  15]\n",
      " [ 37  78 250  29]\n",
      " [ 79  56  24  92]]\n",
      "number of words: 26572\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "score: 0.291204730229\n",
      "con mat: \n",
      "[[  0   0 319   0]\n",
      " [  0   0 389   0]\n",
      " [  0   0 394   0]\n",
      " [  0   0 251   0]]\n",
      "number of words: 26572\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "score: 0.649667405765\n",
      "con mat: \n",
      "[[186  35  40  58]\n",
      " [ 16 343  23   7]\n",
      " [ 46  68 265  15]\n",
      " [106  34  26  85]]\n",
      "number of words: 26572\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "score: 0.682926829268\n",
      "con mat: \n",
      "[[196  37  43  43]\n",
      " [ 14 348  26   1]\n",
      " [ 33  68 285   8]\n",
      " [106  32  18  95]]\n",
      "number of words: 26572\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer(stop_words='english', max_df=0.2)\n",
    "for i in listy_models:\n",
    "    print i\n",
    "    model_score(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Other classifiers\n",
    "\n",
    "Adapt the code from [this example](http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py) to compare across all the classifiers suggested and to display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: NLTK\n",
    "\n",
    "NLTK is a vast library. Can you find some interesting bits to share with classmates?\n",
    "Start here: http://www.nltk.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
